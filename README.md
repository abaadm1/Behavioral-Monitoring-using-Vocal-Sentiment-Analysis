# Behavioral-Monitoring-using-Vocal-Sentiment-Analysis

A speech emotion recognition model specifically tailored for behavioral monitoring in call centers. The objective of this project was to accurately classify speech samples into different emotion categories. To achieve this, the model was designed to extract Mel Cepstral Coefficient (MFCC) features from each speech sample, which was then used to train the Convolutional Neural Network (CNN) for the classification of emotional states of call center agents during customer service interactions.


Technologies: ReactJs, NumPy, Pandas, Matplotlib, Scikit-Learn, Keras, Flask, Firebase
